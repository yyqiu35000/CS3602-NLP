# H2O + StreamingLLM å®ç°è¯´æ˜

æœ¬æ–‡æ¡£è¯´æ˜å¦‚ä½•ä½¿ç”¨ H2O (Heavy Hitter Oracle) ä¸ StreamingLLM çš„ç»„åˆå®ç°ã€‚

## ğŸ“‹ æ–‡ä»¶è¯´æ˜

### æ ¸å¿ƒå®ç°æ–‡ä»¶

| æ–‡ä»¶å                          | è¯´æ˜                                                                                                          |
| ------------------------------- | ------------------------------------------------------------------------------------------------------------- |
| `pythia_streaming_h2o_patch.py` | **H2O æ ¸å¿ƒå®ç°**ã€‚åŒ…å« `H2ODynamicCache` ç±»ï¼ˆå®ç° Sink + Heavy Hitters + Recent Window ç­–ç•¥ï¼‰å’Œåé¦ˆé—­ç¯æœºåˆ¶ã€‚ |
| `bench_streaming_h2o.py`        | **æ ‡å‡†è¯„æµ‹è„šæœ¬**ã€‚å¯¹æ¯” Baselineã€StreamingLLMã€H2O çš„æ€§èƒ½ï¼ˆPPLã€é€Ÿåº¦ã€æ˜¾å­˜ï¼‰ã€‚                                |
| `bench_streaming_h2o_with_int.py`  | **é‡åŒ–è¯„æµ‹è„šæœ¬**ã€‚åœ¨æ ‡å‡†æµ‹è¯„è„šæœ¬çš„åŸºç¡€ä¸Šï¼Œé›†æˆé‡åŒ–åŠŸèƒ½ï¼Œè¿›ä¸€æ­¥é™ä½æ˜¾å­˜ã€‚                                |


## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
pip install -r requirements.txt
pip install bitsandbytes
```

éœ€è¦çš„æ ¸å¿ƒä¾èµ–ï¼š
- `transformers >= 4.30.0`
- `datasets >= 2.0.0`
- `torch >= 2.0.0`
- `accelerate`
- `bitsandbytes`

### 2. è¿è¡Œæ ‡å‡†è¯„æµ‹

å¯¹æ¯” Baselineã€StreamingLLM å’Œ H2O çš„æ€§èƒ½ï¼š

```bash
python bench_streaming_h2o.py
```

**æµ‹è¯•å†…å®¹**ï¼š
- åœ¨ WikiText-2 å’ŒPG-19 æ•°æ®é›†ä¸Šè¯„ä¼°å›°æƒ‘åº¦ï¼ˆPPLï¼‰
- æµ‹é‡ç”Ÿæˆé€Ÿåº¦ã€ååé‡ã€æ˜¾å­˜å ç”¨
- æµ‹è¯•å¤šç§é…ç½®ï¼š
  - `baseline`: æ ‡å‡†å…¨é‡ KV Cache
  - `streaming_8_256`: StreamingLLM (Sink=8, Window=256, æ€»å®¹é‡=264)
  - `streaming_8_512`: StreamingLLM (Sink=8, Window=512, æ€»å®¹é‡=520)
  - `h2o_4_32_264`: H2O (Sink=4, Recent=32, Capacity=264)
  - `h2o_8_32_264`: H2O (Sink=8, Recent=32, Capacity=264)
  - `h2o_8_64_520`: H2O (Sink=8, Recent=64, Capacity=520)

## ğŸ”¬ æ ¸å¿ƒç®—æ³•ï¼šH2O (Heavy Hitter Oracle)

### ç®—æ³•åŸç†

H2O é€šè¿‡åŠ¨æ€é€‰æ‹©æœ€é‡è¦çš„ Key-Value pairs æ¥å‹ç¼© KV Cacheï¼š

```
[Sink Tokens] + [Heavy Hitters] + [Recent Window]
     â†“               â†“                   â†“
   å›ºå®šä¿ç•™      TopK é€‰æ‹©            æ»‘åŠ¨çª—å£
```

### ä¸ StreamingLLM çš„åŒºåˆ«

| ç­–ç•¥         | StreamingLLM                  | H2O                                         |
| ------------ | ----------------------------- | ------------------------------------------- |
| **ä¿ç•™æ–¹å¼** | Sink + Recent Window (å›ºå®š)   | Sink + Heavy Hitters + Recent Window (åŠ¨æ€) |
| **é€‰æ‹©ä¾æ®** | ä½ç½®ï¼ˆæ—¶é—´ï¼‰                  | æ³¨æ„åŠ›æƒé‡ï¼ˆé‡è¦æ€§ï¼‰                        |
| **è®¡ç®—å¼€é”€** | ä½                            | ä¸­ç­‰ï¼ˆéœ€è¦ TopKï¼‰                           |
| **è´¨é‡**     | ä¸­ç­‰ï¼ˆå®¹é‡ 264 æ—¶ PPL 12.09ï¼‰ | æ›´é«˜ï¼ˆå®¹é‡ 264 æ—¶ PPL 8.84ï¼‰                |
| **å®¹é‡å‘½å** | sink + windowï¼ˆæ€»å®¹é‡éœ€ç›¸åŠ ï¼‰ | capacityï¼ˆç›´æ¥è¡¨ç¤ºæ€»å®¹é‡ï¼‰                  |

### åé¦ˆé—­ç¯æœºåˆ¶

H2O é€šè¿‡ **Attention Weights â†’ Cache Update** çš„åé¦ˆé—­ç¯æ¥åŠ¨æ€é€‰æ‹©é‡è¦ tokensï¼š

1. **æ”¶é›†é˜¶æ®µ**ï¼šåœ¨ Attention è®¡ç®—æ—¶ï¼Œè®°å½•æ¯ä¸ª Key è¢«å…³æ³¨çš„ç´¯ç§¯æƒé‡
2. **é€‰æ‹©é˜¶æ®µ**ï¼šå½“ Cache è¶…è¿‡å®¹é‡æ—¶ï¼Œä½¿ç”¨ TopK é€‰å‡ºæƒé‡æœ€é«˜çš„ tokens
3. **æ›´æ–°é˜¶æ®µ**ï¼šä¿ç•™ [Sinks + Heavy Hitters + Recent] å¹¶åŒæ­¥æ›´æ–°åˆ†æ•°

## ğŸ“Š å®éªŒç»“æœ

### æ ‡å‡†è¯„æµ‹ï¼ˆ1000 tokens PPL + 1000 tokens ç”Ÿæˆï¼‰

| Configuration   | Wikitext PPL | PG-19 PPL | Total Time (s) | Avg Attn (ms) | TTFT (s) | TPOT (ms) | Throughput (tok/s) | Peak Mem (GB) |
| :-------------- | :----------- | :-------- | :------------- | :------------ | :------- | :-------- | :----------------- | :------------ |
| baseline        | 6.9805       | 8.5391    | 37.3420        | 138.5542      | 0.1270   | 37.34     | 26.78              | 5.63          |
| streaming_8_256 | 12.0859      | 8.7578    | 35.4912        | 95.8454       | 0.1461   | 35.49     | 28.18              | 5.31          |
| streaming_8_512 | 7.8359       | 8.4844    | 37.3506        | 120.3334      | 0.1422   | 37.35     | 26.77              | 5.36          |
| h2o_4_32_264    | 8.8438       | 10.1562   | 37.8868        | 96.0611       | 0.1551   | 37.89     | 26.39              | 5.31          |
| h2o_8_32_264    | 8.8438       | 10.1562   | 34.3730        | 86.1828       | 0.1528   | 34.37     | 29.09              | 5.31          |
| h2o_8_64_520    | 7.1484       | 9.1953    | 34.7405        | 109.9713      | 0.1408   | 34.74     | 28.78              | 5.37          |



**é…ç½®è¯´æ˜**ï¼š
- `streaming_8_256`: Sink=8, Window=256 (æ€»å®¹é‡ **264**)
- `streaming_8_512`: Sink=8, Window=512 (æ€»å®¹é‡ **520**)
- `h2o_4_32_264`: Sink=4, Recent=32, Heavy Hitters=228 (æ€»å®¹é‡ **264**)
- `h2o_8_32_264`: Sink=8, Recent=32, Heavy Hitters=224 (æ€»å®¹é‡ **264**)
- `h2o_8_64_520`: Sink=8, Recent=64, Heavy Hitters=448 (æ€»å®¹é‡ **520**)

**å…³é”®å‘ç°**ï¼š

1. **PPL è´¨é‡å¯¹æ¯”**ï¼ˆç›¸åŒå®¹é‡ 264ï¼‰ï¼š
   - `streaming_8_256`: PPL **12.09** (+73.2% vs baseline)
   - `h2o_8_32_264`: PPL **8.84** (+26.6% vs baseline)
   - **H2O æ”¹å–„ PPL 26.9%**ï¼ˆ12.09 â†’ 8.84ï¼‰ï¼Œæ˜¾è‘—ä¼˜äº StreamingLLM

2. **PPL è´¨é‡å¯¹æ¯”**ï¼ˆç›¸åŒå®¹é‡ 520ï¼‰ï¼š
   - `streaming_8_512`: PPL **7.84** (+12.3% vs baseline)
   - `h2o_8_64_520`: PPL **7.15** (+2.4% vs baseline)
   - **H2O æ¥è¿‘ baseline è´¨é‡**ï¼Œæ¯” StreamingLLM å¥½ 8.8%

3. **é€Ÿåº¦ä¸æ˜¾å­˜**ï¼š
   - åœ¨264çš„å®¹é‡ä¸‹ï¼Œsink 4 é…ç½®çš„ H2O ååé‡ä½äº StreamingLLMï¼ˆTopK å¼€é”€ï¼‰ï¼Œå’Œ baseline æ¥è¿‘ï¼›sink 8 é…ç½®çš„ h2o ååé‡å’Œ StreamingLLM ç›¸ä»¿ï¼ˆç”±äºéšæœºæ€§ï¼Œæœ‰æ—¶æ›´é«˜ï¼Œæœ‰æ—¶æ›´ä½ï¼‰ï¼Œé«˜äº baselineã€‚
   - **åœ¨520çš„å®¹é‡ä¸‹ï¼ŒH2O ååé‡é«˜äº StreamingLLM ä¸ baselineï¼Œä¸”ä¿æŒäº† PPL ä½äº StreamingLLM**
   - æ˜¾å­˜å ç”¨ï¼šH2O å’Œ StreamingLLM ç›¸å½“ï¼Œéƒ½æ¯” baseline èŠ‚çœçº¦ 5-6%
   - å¹³å‡ Attention æ—¶é—´ï¼šH2O < baselineï¼Œè¯æ˜ Cache å‹ç¼©æœ‰æ•ˆ

4. **ç»¼åˆè¯„ä»·**ï¼š
   - **åœ¨ç›¸åŒ Cache å®¹é‡ä¸‹ï¼ŒH2O çš„ PPL æ˜¾è‘—ä¼˜äº StreamingLLM**
   - h2o_8_64_520 é…ç½®è¾¾åˆ°æ¥è¿‘ baseline çš„è´¨é‡ï¼ŒåŒæ—¶èŠ‚çœæ˜¾å­˜

### é‡åŒ–è¯„æµ‹ (Quantization Benchmark)

```bash
python bench_streaming_h2o_with_int.py
```

æˆ‘ä»¬åœ¨ç³»ç»Ÿå±‚é¢è¿›ä¸€æ­¥æ¢ç´¢äº†é‡åŒ–æŠ€æœ¯ï¼ˆFP16 vs INT8 vs INT4ï¼‰ä¸ H2O ç®—æ³•çš„ååŒæ•ˆæœã€‚

| Configuration        | Wikitext PPL | PG-19 PPL | Total Time (s) | Avg Attn (ms) | TTFT (s) | TPOT (ms) | Throughput (tok/s) | Peak Mem (GB) |
| :------------------- | :----------- | :-------- | :------------- | :------------ | :------- | :-------- | :----------------- | :------------ |
| baseline_fp16        | 6.9805       | 8.5391    | 37.4261        | 142.0857      | 0.1372   | 37.43     | 26.72              | 5.63          |
| streaming_8_256_fp16 | 12.0859      | 8.7578    | 34.5763        | 88.0798       | 0.1439   | 34.58     | 28.92              | 5.31          |
| h2o_8_32_264_fp16    | 8.8438       | 10.1562   | 35.0464        | 89.6381       | 0.1497   | 35.05     | 28.53              | 5.31          |
| baseline_int8        | 7.0508       | 8.5703    | 85.8318        | 148.1701      | 0.1037   | 85.83     | 11.65              | 3.29          |
| streaming_8_256_int8 | 12.1562      | 8.7578    | 85.5524        | 102.2270      | 0.1377   | 85.55     | 11.69              | 2.97          |
| h2o_8_32_264_int8    | 8.8984       | 10.1797   | 87.2948        | 109.1908      | 0.1344   | 87.29     | 11.46              | 2.97          |
| baseline_int4        | 7.2266       | 8.9844    | 45.8627        | 133.3858      | 0.1580   | 45.86     | 21.80              | 2.15          |
| streaming_8_256_int4 | 12.7422      | 9.2109    | 41.9274        | 87.3051       | 0.1621   | 41.93     | 23.85              | 1.85          |
| **h2o_8_32_264_int4**    | **9.1562**       | **10.6484**   | **38.5958**        | **76.1754**       | **0.1723**   | **38.60**     | **25.91**              | **1.85**          |

**å…³é”®ç»“è®º**ï¼š

1.  **INT4 æ˜¯æœ€ä½³å¹³è¡¡ç‚¹ (Sweet Spot)**
    *   **INT8 (11.65 tok/s)**ï¼šç”±äºæ—§ç‰ˆå†…æ ¸è§£å‹å¼€é”€ï¼Œé€Ÿåº¦æ˜¾è‘—æ…¢äº FP16ã€‚
    *   **INT4 (21~25 tok/s)**ï¼šå¾—ç›Šäº `nf4` ä¼˜åŒ–ï¼Œé€Ÿåº¦æ¯” INT8 å¿«ä¸€å€ï¼Œæ¥è¿‘ FP16 æ°´å¹³ã€‚

2.  **æè‡´æ˜¾å­˜ä¼˜åŒ–**
    *   Baseline (FP16): 5.63 GB
    *   H2O (INT4): **1.85 GB** (-67%)
    *   è¿™æ„å‘³ç€ 2.8B å¤§æ¨¡å‹å¯ä»¥åœ¨ **ä¸åˆ° 2GB æ˜¾å­˜** çš„è®¾å¤‡ï¼ˆå¦‚ Jetson Orin Nano, æ ‘è“æ´¾ 5ï¼‰ä¸Šæµç•…è¿è¡Œã€‚

3.  **å…¨åœºæœ€ä½³é…ç½® (MVP): `h2o_8_32_264_int4`**
    *   **é€Ÿåº¦**ï¼š**25.91 tok/s**ï¼Œå‡ ä¹æ— æŸäº FP16 (26.72 tok/s)ã€‚
    *   **è´¨é‡**ï¼šPPL **9.16**ï¼Œè¿œä¼˜äºåŒæ¡ä»¶ä¸‹çš„ StreamingLLM (PPL 12.74)ã€‚
    *   **æ˜¾å­˜**ï¼š**1.85 GB**ï¼Œå…¨åœºæœ€ä½ã€‚
    *   **é²æ£’æ€§**ï¼šè¯æ˜ H2O ç®—æ³•åœ¨ä½ç²¾åº¦é‡åŒ–å™ªå£°ä¸‹ä¾ç„¶èƒ½æœ‰æ•ˆè¯†åˆ« Heavy Hittersã€‚

## ğŸ”§ é…ç½®å‚æ•°è¯´æ˜

### H2O å‚æ•°

```python
enable_h2o_llm(
    model,
    n_sink=8,           # Sink tokens æ•°é‡ï¼ˆåˆå§‹æ³¨æ„åŠ›é”šç‚¹ï¼‰
    recent_window=32,    # Recent window å¤§å°ï¼ˆæœ€æ–° tokensï¼‰
    max_capacity=264,    # æ€» KV Cache å®¹é‡
    debug=False          # æ˜¯å¦æ‰“å°è°ƒè¯•ä¿¡æ¯
)
```

**å‚æ•°è®¡ç®—**ï¼š
```
Heavy Hitters æ•°é‡ = max_capacity - n_sink - recent_window
                  = 264 - 8 - 32 = 224
```

**é‡è¦è¯´æ˜**ï¼š
- **StreamingLLM**: `streaming_{sink}_{window}` è¡¨ç¤ºæ€»å®¹é‡ = sink + window
  - ä¾‹å¦‚ `streaming_8_256` = 8 + 256 = **264** æ€»å®¹é‡
- **H2O**: `h2o_{sink}_{recent}_{capacity}` è¡¨ç¤ºæ€»å®¹é‡ = capacity
  - ä¾‹å¦‚ `h2o_8_32_264` = **264** æ€»å®¹é‡ï¼ˆåŒ…å« 8 sink + 224 heavy + 32 recentï¼‰

### æ¨èé…ç½®

| åœºæ™¯         | é…ç½®           | è¯´æ˜                                    |
| ------------ | -------------- | --------------------------------------- |
| **å¹³è¡¡æ€§èƒ½** | `h2o_8_32_264` | PPL 8.84ï¼Œé€Ÿåº¦ 26.70 tok/sï¼Œæ˜¾å­˜ 5.31GB |
| **é«˜è´¨é‡**   | `h2o_8_64_520` | PPL 7.15ï¼Œæ¥è¿‘ baselineï¼Œæ˜¾å­˜ 5.37GB    |
| **æé™å‹ç¼©** | `h2o_4_32_264` | PPL 8.84ï¼Œé€Ÿåº¦ç•¥æ…¢ï¼Œæ˜¾å­˜ 5.31GB         |

## ğŸ’¡ ä½¿ç”¨å»ºè®®

### ä½•æ—¶ä½¿ç”¨ H2Oï¼Ÿ

âœ… **æ¨èåœºæ™¯**ï¼š
- é•¿ä¸Šä¸‹æ–‡ç”Ÿæˆï¼ˆ> 2000 tokensï¼‰
- éœ€è¦åœ¨å›ºå®š Cache å®¹é‡ä¸‹è·å¾—æ›´å¥½çš„ç”Ÿæˆè´¨é‡
- å¯¹ PPL æœ‰è¾ƒé«˜è¦æ±‚çš„åœºæ™¯
- ç›¸æ¯” StreamingLLMï¼Œå¯ä»¥æ¥å—ç•¥é«˜çš„è®¡ç®—å¼€é”€ï¼ˆTopKï¼‰

âŒ **ä¸æ¨èåœºæ™¯**ï¼š
- çŸ­æ–‡æœ¬ç”Ÿæˆï¼ˆ< 500 tokensï¼‰ï¼ŒTopK å¼€é”€ä¸å€¼å¾—
- å¯¹é€Ÿåº¦æåº¦æ•æ„Ÿçš„å®æ—¶åº”ç”¨ï¼ˆæ¯” StreamingLLM æ…¢çº¦ 5%ï¼‰
- Cache å®¹é‡å……è¶³çš„åœºæ™¯ï¼ˆç›´æ¥ç”¨ baselineï¼‰

### ä¸ StreamingLLM é€‰æ‹©å¯¹æ¯”

| ç‰¹æ€§           | StreamingLLM            | H2O                    |
| -------------- | ----------------------- | ---------------------- |
| **å®ç°å¤æ‚åº¦** | ç®€å•                    | ä¸­ç­‰                   |
| **è®¡ç®—å¼€é”€**   | ä½                      | ä¸­ç­‰ï¼ˆTopK å¼€é”€çº¦ 5%ï¼‰ |
| **PPL è´¨é‡**   | ä¸­ç­‰ï¼ˆ264 å®¹é‡ï¼š12.09ï¼‰ | æ›´é«˜ï¼ˆ264 å®¹é‡ï¼š8.84ï¼‰ |
| **é€Ÿåº¦**       | å¿«ï¼ˆ28.00 tok/sï¼‰       | ç•¥æ…¢ï¼ˆ26.70 tok/sï¼‰    |
| **é€‚ç”¨åœºæ™¯**   | é€Ÿåº¦ä¼˜å…ˆã€ä½è´¨é‡è¦æ±‚    | è´¨é‡ä¼˜å…ˆã€å¯æ¥å—ç•¥æ…¢   |

**æ ¸å¿ƒå·®å¼‚**ï¼šåœ¨ç›¸åŒ Cache å®¹é‡ä¸‹ï¼ŒH2O çš„ PPL æ¯” StreamingLLM ä½ **26.9%**ï¼Œä»£ä»·æ˜¯é€Ÿåº¦æ…¢çº¦ 4.6%ã€‚

## ğŸ› ï¸ API ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€ä½¿ç”¨

```python
from transformers import AutoTokenizer, AutoModelForCausalLM
from pythia_streaming_h2o_patch import enable_h2o_llm

# åŠ è½½æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained(
    "EleutherAI/pythia-2.8b",
    torch_dtype=torch.float16,
    device_map="cuda"
)
tokenizer = AutoTokenizer.from_pretrained("EleutherAI/pythia-2.8b")

# å¯ç”¨ H2O
enable_h2o_llm(model, n_sink=8, recent_window=32, max_capacity=264)

# æ­£å¸¸ä½¿ç”¨ç”Ÿæˆ
inputs = tokenizer("Your prompt here", return_tensors="pt").to("cuda")
outputs = model.generate(**inputs, max_new_tokens=1000)
```

### åˆ‡æ¢é…ç½®

```python
# åˆ‡æ¢åˆ° StreamingLLM
from pythia_streaming_h2o_patch import enable_streaming_llm
enable_streaming_llm(model, n_sink=8, window_size=256)  # æ€»å®¹é‡ 264

# åˆ‡æ¢å› Baseline
from pythia_streaming_h2o_patch import disable_streaming_llm
disable_streaming_llm(model)

# é‡æ–°å¯ç”¨ H2Oï¼ˆä¸åŒå‚æ•°ï¼‰
enable_h2o_llm(model, n_sink=8, recent_window=64, max_capacity=520)  # æ€»å®¹é‡ 520
```

## ğŸ“ å®ç°ç»†èŠ‚

### åé¦ˆé—­ç¯æµç¨‹

```python
# 1. Attention Forward ä¸­å¼ºåˆ¶è¾“å‡ºæƒé‡
force_output_attentions = output_attentions or hasattr(layer_past, "update_scores")

# 2. è®¡ç®— Attention
attn_output, attn_weights = attention_interface(...)

# 3. åé¦ˆåˆ° Cache
if hasattr(layer_past, "update_scores") and attn_weights is not None:
    layer_past.update_scores(attn_weights, self.layer_idx)

# 4. Cache åœ¨ update() æ—¶æ‰§è¡Œ TopK é€‰æ‹©
```

### Lazy Eviction ç­–ç•¥

ä¸ºäº†é¿å…é¢‘ç¹çš„ TopK è®¡ç®—å’Œå†…å­˜æ‹·è´ï¼š

```python
if current_len > max_capacity + 64:  # è¶…è¿‡å®¹é‡ + Buffer
    # æ‰§è¡Œé©±é€
    heavy_hitters = topk_select(scores)
    keep_indices = [sinks, heavy_hitters, recent]
    cache = cache[:, :, keep_indices, :]
```

## ğŸ¤ è´¡çŒ®

H2O å®ç°åŸºäºä»¥ä¸‹å·¥ä½œï¼š
- **H2O**: [H2O: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models](https://arxiv.org/abs/2306.14048)
- **StreamingLLM**: [Efficient Streaming Language Models with Attention Sinks](https://arxiv.org/abs/2309.17453)
