# H2O + StreamingLLM å®ç°è¯´æ˜

æœ¬æ–‡æ¡£è¯´æ˜å¦‚ä½•ä½¿ç”¨ H2O (Heavy Hitter Oracle) ä¸ StreamingLLM çš„ç»„åˆå®ç°ã€‚

## ğŸ“‹ æ–‡ä»¶è¯´æ˜

### æ ¸å¿ƒå®ç°æ–‡ä»¶

| æ–‡ä»¶å                          | è¯´æ˜                                                                                                          |
| ------------------------------- | ------------------------------------------------------------------------------------------------------------- |
| `pythia_streaming_h2o_patch.py` | **H2O æ ¸å¿ƒå®ç°**ã€‚åŒ…å« `H2ODynamicCache` ç±»ï¼ˆå®ç° Sink + Heavy Hitters + Recent Window ç­–ç•¥ï¼‰å’Œåé¦ˆé—­ç¯æœºåˆ¶ã€‚ |
| `bench_streaming_h2o.py`        | **æ ‡å‡†è¯„æµ‹è„šæœ¬**ã€‚å¯¹æ¯” Baselineã€StreamingLLMã€H2O çš„æ€§èƒ½ï¼ˆPPLã€é€Ÿåº¦ã€æ˜¾å­˜ï¼‰ã€‚                                |
| `long_context_stress_test.py`   | **é•¿æ–‡æœ¬å‹åŠ›æµ‹è¯•**ã€‚éªŒè¯ H2O çªç ´æ¨¡å‹ä½ç½®ç¼–ç é™åˆ¶çš„èƒ½åŠ›ã€‚                                                     |

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
pip install -r requirements.txt
```

éœ€è¦çš„æ ¸å¿ƒä¾èµ–ï¼š
- `transformers >= 4.30.0`
- `datasets >= 2.0.0`
- `torch >= 2.0.0`
- `accelerate`

### 2. è¿è¡Œæ ‡å‡†è¯„æµ‹

å¯¹æ¯” Baselineã€StreamingLLM å’Œ H2O çš„æ€§èƒ½ï¼š

```bash
python bench_streaming_h2o.py
```

**æµ‹è¯•å†…å®¹**ï¼š
- åœ¨ WikiText-2 å’ŒPG-19 æ•°æ®é›†ä¸Šè¯„ä¼°å›°æƒ‘åº¦ï¼ˆPPLï¼‰
- æµ‹é‡ç”Ÿæˆé€Ÿåº¦ã€ååé‡ã€æ˜¾å­˜å ç”¨
- æµ‹è¯•å¤šç§é…ç½®ï¼š
  - `baseline`: æ ‡å‡†å…¨é‡ KV Cache
  - `streaming_8_256`: StreamingLLM (Sink=8, Window=256, æ€»å®¹é‡=264)
  - `streaming_8_512`: StreamingLLM (Sink=8, Window=512, æ€»å®¹é‡=520)
  - `h2o_4_32_264`: H2O (Sink=4, Recent=32, Capacity=264)
  - `h2o_8_32_264`: H2O (Sink=8, Recent=32, Capacity=264)
  - `h2o_8_64_520`: H2O (Sink=8, Recent=64, Capacity=520)

## ğŸ”¬ æ ¸å¿ƒç®—æ³•ï¼šH2O (Heavy Hitter Oracle)

### ç®—æ³•åŸç†

H2O é€šè¿‡åŠ¨æ€é€‰æ‹©æœ€é‡è¦çš„ Key-Value pairs æ¥å‹ç¼© KV Cacheï¼š

```
[Sink Tokens] + [Heavy Hitters] + [Recent Window]
     â†“               â†“                   â†“
   å›ºå®šä¿ç•™      TopK é€‰æ‹©            æ»‘åŠ¨çª—å£
```

### ä¸ StreamingLLM çš„åŒºåˆ«

| ç­–ç•¥         | StreamingLLM                  | H2O                                         |
| ------------ | ----------------------------- | ------------------------------------------- |
| **ä¿ç•™æ–¹å¼** | Sink + Recent Window (å›ºå®š)   | Sink + Heavy Hitters + Recent Window (åŠ¨æ€) |
| **é€‰æ‹©ä¾æ®** | ä½ç½®ï¼ˆæ—¶é—´ï¼‰                  | æ³¨æ„åŠ›æƒé‡ï¼ˆé‡è¦æ€§ï¼‰                        |
| **è®¡ç®—å¼€é”€** | ä½                            | ä¸­ç­‰ï¼ˆéœ€è¦ TopKï¼‰                           |
| **è´¨é‡**     | ä¸­ç­‰ï¼ˆå®¹é‡ 264 æ—¶ PPL 12.09ï¼‰ | æ›´é«˜ï¼ˆå®¹é‡ 264 æ—¶ PPL 8.84ï¼‰                |
| **å®¹é‡å‘½å** | sink + windowï¼ˆæ€»å®¹é‡éœ€ç›¸åŠ ï¼‰ | capacityï¼ˆç›´æ¥è¡¨ç¤ºæ€»å®¹é‡ï¼‰                  |

### åé¦ˆé—­ç¯æœºåˆ¶

H2O é€šè¿‡ **Attention Weights â†’ Cache Update** çš„åé¦ˆé—­ç¯æ¥åŠ¨æ€é€‰æ‹©é‡è¦ tokensï¼š

1. **æ”¶é›†é˜¶æ®µ**ï¼šåœ¨ Attention è®¡ç®—æ—¶ï¼Œè®°å½•æ¯ä¸ª Key è¢«å…³æ³¨çš„ç´¯ç§¯æƒé‡
2. **é€‰æ‹©é˜¶æ®µ**ï¼šå½“ Cache è¶…è¿‡å®¹é‡æ—¶ï¼Œä½¿ç”¨ TopK é€‰å‡ºæƒé‡æœ€é«˜çš„ tokens
3. **æ›´æ–°é˜¶æ®µ**ï¼šä¿ç•™ [Sinks + Heavy Hitters + Recent] å¹¶åŒæ­¥æ›´æ–°åˆ†æ•°

## ğŸ“Š å®éªŒç»“æœ

### æ ‡å‡†è¯„æµ‹ï¼ˆ1000 tokens PPL + 1000 tokens ç”Ÿæˆï¼‰

| é…ç½®             | WikiText PPL | PG-19 PPL | ååé‡ (tok/s) | å¹³å‡ Attn (ms) | å³°å€¼æ˜¾å­˜ (GB) |
| ---------------- | ------------ | --------- | -------------- | -------------- | ------------- |
| baseline         | 6.98         | 1.16      | 24.90          | 154.39         | 5.63          |
| streaming_8_256  | 12.09        | 1.16      | 28.00          | 88.41          | 5.31          |
| streaming_8_512  | 7.84         | 1.16      | 24.16          | 125.61         | 5.36          |
| **h2o_4_32_264** | **8.84**     | **1.46**  | **24.65**      | **107.01**     | **5.31**      |
| **h2o_8_32_264** | **8.84**     | **1.46**  | **26.70**      | **99.81**      | **5.31**      |
| **h2o_8_64_520** | **7.15**     | **1.19**  | **25.65**      | **122.07**     | **5.37**      |


| Configuration   | Wikitext PPL | PG-19 PPL | Total Time (s) | Avg Attn (ms) | TTFT (s) | TPOT (ms) | Throughput (tok/s) | Peak Mem (GB) |
| :-------------- | :----------- | :-------- | :------------- | :------------ | :------- | :-------- | :----------------- | :------------ |
| baseline        | 6.9805       | 1.1611    | 40.1552        | 154.3918      | 0.1432   | 40.16     | 24.90              | 5.63          |
| streaming_8_256 | 12.0859      | 1.1641    | 35.7196        | 88.4128       | 0.1538   | 35.72     | 28.00              | 5.31          |
| streaming_8_512 | 7.8359       | 1.1631    | 41.3973        | 125.6094      | 0.1525   | 41.40     | 24.16              | 5.36          |
| h2o_4_32_264    | 8.8438       | 1.4570    | 40.5740        | 107.0145      | 0.1676   | 40.57     | 24.65              | 5.31          |
| h2o_8_32_264    | 8.8438       | 1.4570    | 37.4556        | 99.8069       | 0.1671   | 37.46     | 26.70              | 5.31          |
| h2o_8_64_520    | 7.1484       | 1.1943    | 38.9929        | 122.0691      | 0.1521   | 38.99     | 25.65              | 5.37          |



**é…ç½®è¯´æ˜**ï¼š
- `streaming_8_256`: Sink=8, Window=256 (æ€»å®¹é‡ **264**)
- `streaming_8_512`: Sink=8, Window=512 (æ€»å®¹é‡ **520**)
- `h2o_4_32_264`: Sink=4, Recent=32, Heavy Hitters=228 (æ€»å®¹é‡ **264**)
- `h2o_8_32_264`: Sink=8, Recent=32, Heavy Hitters=224 (æ€»å®¹é‡ **264**)
- `h2o_8_64_520`: Sink=8, Recent=64, Heavy Hitters=448 (æ€»å®¹é‡ **520**)

**å…³é”®å‘ç°**ï¼š

1. **PPL è´¨é‡å¯¹æ¯”**ï¼ˆç›¸åŒå®¹é‡ 264ï¼‰ï¼š
   - `streaming_8_256`: PPL **12.09** (+73.2% vs baseline)
   - `h2o_8_32_264`: PPL **8.84** (+26.6% vs baseline)
   - **H2O æ”¹å–„ PPL 26.9%**ï¼ˆ12.09 â†’ 8.84ï¼‰ï¼Œæ˜¾è‘—ä¼˜äº StreamingLLM

2. **PPL è´¨é‡å¯¹æ¯”**ï¼ˆç›¸åŒå®¹é‡ 520ï¼‰ï¼š
   - `streaming_8_512`: PPL **7.84** (+12.3% vs baseline)
   - `h2o_8_64_520`: PPL **7.15** (+2.4% vs baseline)
   - **H2O æ¥è¿‘ baseline è´¨é‡**ï¼Œæ¯” StreamingLLM å¥½ 8.8%

3. **é€Ÿåº¦ä¸æ˜¾å­˜**ï¼š
   - åœ¨264çš„å®¹é‡ä¸‹ï¼ŒH2O ååé‡ç•¥ä½äº StreamingLLMï¼ˆTopK å¼€é”€ï¼‰ï¼Œä½†ä¼˜äº baseline
   - **åœ¨520çš„å®¹é‡ä¸‹ï¼ŒH2O ååé‡é«˜äº StreamingLLM ä¸ baselineï¼Œä¸”ä¿æŒäº† PPL ä½äº StreamingLLM**
   - æ˜¾å­˜å ç”¨ï¼šH2O å’Œ StreamingLLM ç›¸å½“ï¼Œéƒ½æ¯” baseline èŠ‚çœçº¦ 5-6%
   - å¹³å‡ Attention æ—¶é—´ï¼šH2O < baselineï¼Œè¯æ˜ Cache å‹ç¼©æœ‰æ•ˆ

4. **ç»¼åˆè¯„ä»·**ï¼š
   - **åœ¨ç›¸åŒ Cache å®¹é‡ä¸‹ï¼ŒH2O çš„ PPL æ˜¾è‘—ä¼˜äº StreamingLLM**
   - h2o_8_64_520 é…ç½®è¾¾åˆ°æ¥è¿‘ baseline çš„è´¨é‡ï¼ŒåŒæ—¶èŠ‚çœæ˜¾å­˜

## ğŸ”§ é…ç½®å‚æ•°è¯´æ˜

### H2O å‚æ•°

```python
enable_h2o_llm(
    model,
    n_sink=8,           # Sink tokens æ•°é‡ï¼ˆåˆå§‹æ³¨æ„åŠ›é”šç‚¹ï¼‰
    recent_window=32,    # Recent window å¤§å°ï¼ˆæœ€æ–° tokensï¼‰
    max_capacity=264,    # æ€» KV Cache å®¹é‡
    debug=False          # æ˜¯å¦æ‰“å°è°ƒè¯•ä¿¡æ¯
)
```

**å‚æ•°è®¡ç®—**ï¼š
```
Heavy Hitters æ•°é‡ = max_capacity - n_sink - recent_window
                  = 264 - 8 - 32 = 224
```

**é‡è¦è¯´æ˜**ï¼š
- **StreamingLLM**: `streaming_{sink}_{window}` è¡¨ç¤ºæ€»å®¹é‡ = sink + window
  - ä¾‹å¦‚ `streaming_8_256` = 8 + 256 = **264** æ€»å®¹é‡
- **H2O**: `h2o_{sink}_{recent}_{capacity}` è¡¨ç¤ºæ€»å®¹é‡ = capacity
  - ä¾‹å¦‚ `h2o_8_32_264` = **264** æ€»å®¹é‡ï¼ˆåŒ…å« 8 sink + 224 heavy + 32 recentï¼‰

### æ¨èé…ç½®

| åœºæ™¯         | é…ç½®           | è¯´æ˜                                    |
| ------------ | -------------- | --------------------------------------- |
| **å¹³è¡¡æ€§èƒ½** | `h2o_8_32_264` | PPL 8.84ï¼Œé€Ÿåº¦ 26.70 tok/sï¼Œæ˜¾å­˜ 5.31GB |
| **é«˜è´¨é‡**   | `h2o_8_64_520` | PPL 7.15ï¼Œæ¥è¿‘ baselineï¼Œæ˜¾å­˜ 5.37GB    |
| **æé™å‹ç¼©** | `h2o_4_32_264` | PPL 8.84ï¼Œé€Ÿåº¦ç•¥æ…¢ï¼Œæ˜¾å­˜ 5.31GB         |

## ğŸ’¡ ä½¿ç”¨å»ºè®®

### ä½•æ—¶ä½¿ç”¨ H2Oï¼Ÿ

âœ… **æ¨èåœºæ™¯**ï¼š
- é•¿ä¸Šä¸‹æ–‡ç”Ÿæˆï¼ˆ> 2000 tokensï¼‰
- éœ€è¦åœ¨å›ºå®š Cache å®¹é‡ä¸‹è·å¾—æ›´å¥½çš„ç”Ÿæˆè´¨é‡
- å¯¹ PPL æœ‰è¾ƒé«˜è¦æ±‚çš„åœºæ™¯
- ç›¸æ¯” StreamingLLMï¼Œå¯ä»¥æ¥å—ç•¥é«˜çš„è®¡ç®—å¼€é”€ï¼ˆTopKï¼‰

âŒ **ä¸æ¨èåœºæ™¯**ï¼š
- çŸ­æ–‡æœ¬ç”Ÿæˆï¼ˆ< 500 tokensï¼‰ï¼ŒTopK å¼€é”€ä¸å€¼å¾—
- å¯¹é€Ÿåº¦æåº¦æ•æ„Ÿçš„å®æ—¶åº”ç”¨ï¼ˆæ¯” StreamingLLM æ…¢çº¦ 5%ï¼‰
- Cache å®¹é‡å……è¶³çš„åœºæ™¯ï¼ˆç›´æ¥ç”¨ baselineï¼‰

### ä¸ StreamingLLM é€‰æ‹©å¯¹æ¯”

| ç‰¹æ€§           | StreamingLLM            | H2O                    |
| -------------- | ----------------------- | ---------------------- |
| **å®ç°å¤æ‚åº¦** | ç®€å•                    | ä¸­ç­‰                   |
| **è®¡ç®—å¼€é”€**   | ä½                      | ä¸­ç­‰ï¼ˆTopK å¼€é”€çº¦ 5%ï¼‰ |
| **PPL è´¨é‡**   | ä¸­ç­‰ï¼ˆ264 å®¹é‡ï¼š12.09ï¼‰ | æ›´é«˜ï¼ˆ264 å®¹é‡ï¼š8.84ï¼‰ |
| **é€Ÿåº¦**       | å¿«ï¼ˆ28.00 tok/sï¼‰       | ç•¥æ…¢ï¼ˆ26.70 tok/sï¼‰    |
| **é€‚ç”¨åœºæ™¯**   | é€Ÿåº¦ä¼˜å…ˆã€ä½è´¨é‡è¦æ±‚    | è´¨é‡ä¼˜å…ˆã€å¯æ¥å—ç•¥æ…¢   |

**æ ¸å¿ƒå·®å¼‚**ï¼šåœ¨ç›¸åŒ Cache å®¹é‡ä¸‹ï¼ŒH2O çš„ PPL æ¯” StreamingLLM ä½ **26.9%**ï¼Œä»£ä»·æ˜¯é€Ÿåº¦æ…¢çº¦ 4.6%ã€‚

## ğŸ› ï¸ API ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€ä½¿ç”¨

```python
from transformers import AutoTokenizer, AutoModelForCausalLM
from pythia_streaming_h2o_patch import enable_h2o_llm

# åŠ è½½æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained(
    "EleutherAI/pythia-2.8b",
    torch_dtype=torch.float16,
    device_map="cuda"
)
tokenizer = AutoTokenizer.from_pretrained("EleutherAI/pythia-2.8b")

# å¯ç”¨ H2O
enable_h2o_llm(model, n_sink=8, recent_window=32, max_capacity=264)

# æ­£å¸¸ä½¿ç”¨ç”Ÿæˆ
inputs = tokenizer("Your prompt here", return_tensors="pt").to("cuda")
outputs = model.generate(**inputs, max_new_tokens=1000)
```

### åˆ‡æ¢é…ç½®

```python
# åˆ‡æ¢åˆ° StreamingLLM
from pythia_streaming_h2o_patch import enable_streaming_llm
enable_streaming_llm(model, n_sink=8, window_size=256)  # æ€»å®¹é‡ 264

# åˆ‡æ¢å› Baseline
from pythia_streaming_h2o_patch import disable_streaming_llm
disable_streaming_llm(model)

# é‡æ–°å¯ç”¨ H2Oï¼ˆä¸åŒå‚æ•°ï¼‰
enable_h2o_llm(model, n_sink=8, recent_window=64, max_capacity=520)  # æ€»å®¹é‡ 520
```

## ğŸ“ å®ç°ç»†èŠ‚

### åé¦ˆé—­ç¯æµç¨‹

```python
# 1. Attention Forward ä¸­å¼ºåˆ¶è¾“å‡ºæƒé‡
force_output_attentions = output_attentions or hasattr(layer_past, "update_scores")

# 2. è®¡ç®— Attention
attn_output, attn_weights = attention_interface(...)

# 3. åé¦ˆåˆ° Cache
if hasattr(layer_past, "update_scores") and attn_weights is not None:
    layer_past.update_scores(attn_weights, self.layer_idx)

# 4. Cache åœ¨ update() æ—¶æ‰§è¡Œ TopK é€‰æ‹©
```

### Lazy Eviction ç­–ç•¥

ä¸ºäº†é¿å…é¢‘ç¹çš„ TopK è®¡ç®—å’Œå†…å­˜æ‹·è´ï¼š

```python
if current_len > max_capacity + 64:  # è¶…è¿‡å®¹é‡ + Buffer
    # æ‰§è¡Œé©±é€
    heavy_hitters = topk_select(scores)
    keep_indices = [sinks, heavy_hitters, recent]
    cache = cache[:, :, keep_indices, :]
```

## ğŸ¤ è´¡çŒ®

H2O å®ç°åŸºäºä»¥ä¸‹å·¥ä½œï¼š
- **H2O**: [H2O: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models](https://arxiv.org/abs/2306.14048)
- **StreamingLLM**: [Efficient Streaming Language Models with Attention Sinks](https://arxiv.org/abs/2309.17453)
