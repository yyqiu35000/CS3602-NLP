# H2O + StreamingLLM å®ç°è¯´æ˜

æœ¬æ–‡æ¡£è¯´æ˜å¦‚ä½•ä½¿ç”¨ H2O (Heavy Hitter Oracle) ä¸ StreamingLLM çš„ç»„åˆå®ç°ã€‚

## ğŸ“‹ æ–‡ä»¶è¯´æ˜

### æ ¸å¿ƒå®ç°æ–‡ä»¶

| æ–‡ä»¶å                          | è¯´æ˜                                                                                                          |
| ------------------------------- | ------------------------------------------------------------------------------------------------------------- |
| `pythia_streaming_h2o_patch.py` | **H2O æ ¸å¿ƒå®ç°**ã€‚åŒ…å« `H2ODynamicCache` ç±»ï¼ˆå®ç° Sink + Heavy Hitters + Recent Window ç­–ç•¥ï¼‰å’Œåé¦ˆé—­ç¯æœºåˆ¶ã€‚ |
| `bench_streaming_h2o.py`        | **æ ‡å‡†è¯„æµ‹è„šæœ¬**ã€‚å¯¹æ¯” Baselineã€StreamingLLMã€H2O çš„æ€§èƒ½ï¼ˆPPLã€é€Ÿåº¦ã€æ˜¾å­˜ï¼‰ã€‚                                |
| `long_context_stress_test.py`   | **é•¿æ–‡æœ¬å‹åŠ›æµ‹è¯•**ã€‚éªŒè¯ H2O çªç ´æ¨¡å‹ä½ç½®ç¼–ç é™åˆ¶çš„èƒ½åŠ›ã€‚                                                     |

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
pip install -r requirements.txt
```

éœ€è¦çš„æ ¸å¿ƒä¾èµ–ï¼š
- `transformers >= 4.30.0`
- `datasets >= 2.0.0`
- `torch >= 2.0.0`
- `accelerate`

### 2. è¿è¡Œæ ‡å‡†è¯„æµ‹

å¯¹æ¯” Baselineã€StreamingLLM å’Œ H2O çš„æ€§èƒ½ï¼š

```bash
python bench_streaming_h2o.py
```

**æµ‹è¯•å†…å®¹**ï¼š
- åœ¨ WikiText-2 å’Œ PG-19 æ•°æ®é›†ä¸Šè¯„ä¼°å›°æƒ‘åº¦ï¼ˆPPLï¼‰
- æµ‹é‡ç”Ÿæˆé€Ÿåº¦ã€ååé‡ã€æ˜¾å­˜å ç”¨
- æµ‹è¯•å¤šç§é…ç½®ï¼š
  - `baseline`: æ ‡å‡†å…¨é‡ KV Cache
  - `streaming_8_256`: StreamingLLM (Sink=8, Window=256)
  - `h2o_8_32_256`: H2O (Sink=8, Recent=32, Capacity=256)
  - `h2o_8_64_512`: H2O (Sink=8, Recent=64, Capacity=512)

### 3. è¿è¡Œé•¿æ–‡æœ¬å‹åŠ›æµ‹è¯•

éªŒè¯ H2O åœ¨é•¿æ–‡æœ¬ç”Ÿæˆä¸­çš„ä¼˜åŠ¿ï¼š

```bash
python long_context_stress_test.py
```

**æµ‹è¯•å†…å®¹**ï¼š
- æ¸è¿›å¼é•¿åº¦æµ‹è¯•ï¼ˆ1000 â†’ 10000 tokensï¼‰
- éªŒè¯ä½ç½®ç¼–ç çªç ´èƒ½åŠ›
- å¯¹æ¯” Baseline å’Œ H2O çš„ç¨³å®šæ€§

## ğŸ”¬ æ ¸å¿ƒç®—æ³•ï¼šH2O (Heavy Hitter Oracle)

### ç®—æ³•åŸç†

H2O é€šè¿‡åŠ¨æ€é€‰æ‹©æœ€é‡è¦çš„ Key-Value pairs æ¥å‹ç¼© KV Cacheï¼š

```
[Sink Tokens] + [Heavy Hitters] + [Recent Window]
     â†“               â†“                   â†“
   å›ºå®šä¿ç•™      TopK é€‰æ‹©            æ»‘åŠ¨çª—å£
```

### ä¸ StreamingLLM çš„åŒºåˆ«

| ç­–ç•¥         | StreamingLLM                | H2O                                         |
| ------------ | --------------------------- | ------------------------------------------- |
| **ä¿ç•™æ–¹å¼** | Sink + Recent Window (å›ºå®š) | Sink + Heavy Hitters + Recent Window (åŠ¨æ€) |
| **é€‰æ‹©ä¾æ®** | ä½ç½®ï¼ˆæ—¶é—´ï¼‰                | æ³¨æ„åŠ›æƒé‡ï¼ˆé‡è¦æ€§ï¼‰                        |
| **è®¡ç®—å¼€é”€** | ä½                          | ä¸­ç­‰ï¼ˆéœ€è¦ TopKï¼‰                           |
| **è´¨é‡**     | ä¸­ç­‰                        | æ›´é«˜                                        |

### åé¦ˆé—­ç¯æœºåˆ¶

H2O é€šè¿‡ **Attention Weights â†’ Cache Update** çš„åé¦ˆé—­ç¯æ¥åŠ¨æ€é€‰æ‹©é‡è¦ tokensï¼š

1. **æ”¶é›†é˜¶æ®µ**ï¼šåœ¨ Attention è®¡ç®—æ—¶ï¼Œè®°å½•æ¯ä¸ª Key è¢«å…³æ³¨çš„ç´¯ç§¯æƒé‡
2. **é€‰æ‹©é˜¶æ®µ**ï¼šå½“ Cache è¶…è¿‡å®¹é‡æ—¶ï¼Œä½¿ç”¨ TopK é€‰å‡ºæƒé‡æœ€é«˜çš„ tokens
3. **æ›´æ–°é˜¶æ®µ**ï¼šä¿ç•™ [Sinks + Heavy Hitters + Recent] å¹¶åŒæ­¥æ›´æ–°åˆ†æ•°

## ğŸ“Š å®éªŒç»“æœ

### æ ‡å‡†è¯„æµ‹ï¼ˆ1000 tokens ç”Ÿæˆï¼‰

| é…ç½®             | WikiText PPL | ååé‡ (tok/s) | å³°å€¼æ˜¾å­˜ (GB) |
| ---------------- | ------------ | -------------- | ------------- |
| baseline         | 6.99         | 26.51          | 5.48          |
| streaming_8_256  | 32.24        | 28.01          | 5.31          |
| **h2o_8_32_256** | **13.55**    | **24.16**      | **5.36**      |
| **h2o_8_64_512** | **6.98**     | **24.42**      | **5.36**      |

**å…³é”®å‘ç°**ï¼š
- H2O æ˜¾è‘—æ”¹å–„ PPLï¼ˆ32.24 â†’ 13.55ï¼Œæå‡ 58%ï¼‰
- h2o_8_64_512 é…ç½®è¾¾åˆ°æ¥è¿‘ baseline çš„è´¨é‡ï¼ŒåŒæ—¶èŠ‚çœæ˜¾å­˜

### é•¿æ–‡æœ¬å‹åŠ›æµ‹è¯•

| é…ç½®             | ç”Ÿæˆé•¿åº¦  | ååé‡ (tok/s) | çŠ¶æ€         |
| ---------------- | --------- | -------------- | ------------ |
| baseline         | 1000      | 20.93          | âœ…            |
| baseline         | 1500      | 22.74          | âœ… (æ¥è¿‘æé™) |
| **h2o_8_32_256** | **1000**  | **24.57**      | âœ…            |
| **h2o_8_32_256** | **5000**  | **28.07**      | âœ…            |
| **h2o_8_32_256** | **10000** | **27.29**      | âœ…            |

**å…³é”®å‘ç°**ï¼š
- **çªç ´ä½ç½®ç¼–ç é™åˆ¶**ï¼šPythia-2.8b è®­ç»ƒæœ€å¤§é•¿åº¦ 2048ï¼Œä½† H2O å¯ç¨³å®šç”Ÿæˆ 10000+ tokens
- **æ€§èƒ½ä¼˜åŠ¿æ˜¾ç°**ï¼šåœ¨é•¿æ–‡æœ¬åœºæ™¯ä¸‹ï¼ŒH2O ååé‡æ¯” baseline é«˜ 23.4%
- **æ˜¾å­˜æ’å®š**ï¼šH2O æ˜¾å­˜ä¿æŒåœ¨ 5.28GBï¼Œä¸éšç”Ÿæˆé•¿åº¦å¢é•¿

## ğŸ”§ é…ç½®å‚æ•°è¯´æ˜

### H2O å‚æ•°

```python
enable_h2o_llm(
    model,
    n_sink=8,           # Sink tokens æ•°é‡ï¼ˆåˆå§‹æ³¨æ„åŠ›é”šç‚¹ï¼‰
    recent_window=32,    # Recent window å¤§å°ï¼ˆæœ€æ–° tokensï¼‰
    max_capacity=256,    # æ€» KV Cache å®¹é‡
    debug=False          # æ˜¯å¦æ‰“å°è°ƒè¯•ä¿¡æ¯
)
```

**å‚æ•°è®¡ç®—**ï¼š
```
Heavy Hitters æ•°é‡ = max_capacity - n_sink - recent_window
                  = 256 - 8 - 32 = 216
```

### æ¨èé…ç½®

| åœºæ™¯         | é…ç½®           | è¯´æ˜                           |
| ------------ | -------------- | ------------------------------ |
| **å¹³è¡¡æ€§èƒ½** | `h2o_8_32_256` | é€‚åˆå¤§å¤šæ•°åœºæ™¯ï¼Œé€Ÿåº¦å¿«         |
| **é«˜è´¨é‡**   | `h2o_8_64_512` | æ¥è¿‘ baseline è´¨é‡ï¼Œæ˜¾å­˜ä»å¯æ§ |
| **æé™å‹ç¼©** | `h2o_4_16_128` | æœ€å°æ˜¾å­˜å ç”¨ï¼Œè´¨é‡æœ‰æŸ         |

## ğŸ’¡ ä½¿ç”¨å»ºè®®

### ä½•æ—¶ä½¿ç”¨ H2Oï¼Ÿ

âœ… **æ¨èåœºæ™¯**ï¼š
- é•¿ä¸Šä¸‹æ–‡ç”Ÿæˆï¼ˆ> 2000 tokensï¼‰
- éœ€è¦çªç ´æ¨¡å‹è®­ç»ƒé•¿åº¦é™åˆ¶
- å¯¹ç”Ÿæˆè´¨é‡æœ‰è¾ƒé«˜è¦æ±‚
- æ˜¾å­˜å—é™ä½†éœ€è¦å¤„ç†é•¿æ–‡æœ¬

âŒ **ä¸æ¨èåœºæ™¯**ï¼š
- çŸ­æ–‡æœ¬ç”Ÿæˆï¼ˆ< 500 tokensï¼‰ï¼ŒTopK å¼€é”€ä¸å€¼å¾—
- å¯¹é€Ÿåº¦æåº¦æ•æ„Ÿçš„å®æ—¶åº”ç”¨
- å·²æœ‰å……è¶³æ˜¾å­˜çš„åœºæ™¯

### ä¸ StreamingLLM é€‰æ‹©å¯¹æ¯”

| ç‰¹æ€§           | StreamingLLM         | H2O                |
| -------------- | -------------------- | ------------------ |
| **å®ç°å¤æ‚åº¦** | ç®€å•                 | ä¸­ç­‰               |
| **è®¡ç®—å¼€é”€**   | ä½                   | ä¸­ç­‰               |
| **è´¨é‡**       | ä¸­ç­‰                 | æ›´é«˜               |
| **é€‚ç”¨åœºæ™¯**   | è¶…é•¿æ–‡æœ¬ã€ä½è´¨é‡è¦æ±‚ | é•¿æ–‡æœ¬ã€é«˜è´¨é‡è¦æ±‚ |

## ğŸ› ï¸ API ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€ä½¿ç”¨

```python
from transformers import AutoTokenizer, AutoModelForCausalLM
from pythia_streaming_h2o_patch import enable_h2o_llm

# åŠ è½½æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained(
    "EleutherAI/pythia-2.8b",
    torch_dtype=torch.float16,
    device_map="cuda"
)
tokenizer = AutoTokenizer.from_pretrained("EleutherAI/pythia-2.8b")

# å¯ç”¨ H2O
enable_h2o_llm(model, n_sink=8, recent_window=32, max_capacity=256)

# æ­£å¸¸ä½¿ç”¨ç”Ÿæˆ
inputs = tokenizer("Your prompt here", return_tensors="pt").to("cuda")
outputs = model.generate(**inputs, max_new_tokens=1000)
```

### åˆ‡æ¢é…ç½®

```python
# åˆ‡æ¢åˆ° StreamingLLM
from pythia_streaming_h2o_patch import enable_streaming_llm
enable_streaming_llm(model, n_sink=8, window_size=256)

# åˆ‡æ¢å› Baseline
from pythia_streaming_h2o_patch import disable_streaming_llm
disable_streaming_llm(model)

# é‡æ–°å¯ç”¨ H2Oï¼ˆä¸åŒå‚æ•°ï¼‰
enable_h2o_llm(model, n_sink=8, recent_window=64, max_capacity=512)
```

## ğŸ“ å®ç°ç»†èŠ‚

### åé¦ˆé—­ç¯æµç¨‹

```python
# 1. Attention Forward ä¸­å¼ºåˆ¶è¾“å‡ºæƒé‡
force_output_attentions = output_attentions or hasattr(layer_past, "update_scores")

# 2. è®¡ç®— Attention
attn_output, attn_weights = attention_interface(...)

# 3. åé¦ˆåˆ° Cache
if hasattr(layer_past, "update_scores") and attn_weights is not None:
    layer_past.update_scores(attn_weights, self.layer_idx)

# 4. Cache åœ¨ update() æ—¶æ‰§è¡Œ TopK é€‰æ‹©
```

### Lazy Eviction ç­–ç•¥

ä¸ºäº†é¿å…é¢‘ç¹çš„ TopK è®¡ç®—å’Œå†…å­˜æ‹·è´ï¼š

```python
if current_len > max_capacity + 64:  # è¶…è¿‡å®¹é‡ + Buffer
    # æ‰§è¡Œé©±é€
    heavy_hitters = topk_select(scores)
    keep_indices = [sinks, heavy_hitters, recent]
    cache = cache[:, :, keep_indices, :]
```

## ğŸ¤ è´¡çŒ®

H2O å®ç°åŸºäºä»¥ä¸‹å·¥ä½œï¼š
- **è®ºæ–‡**: [H2O: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models](https://arxiv.org/abs/2306.14048)
- **StreamingLLM**: [Efficient Streaming Language Models with Attention Sinks](https://arxiv.org/abs/2309.17453)

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ª MIT è®¸å¯è¯ã€‚
